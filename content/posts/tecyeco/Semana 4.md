---
title: "Semana 4"
date: 2020-06-08T08:06:25+06:00
description: Semana 4
hero: /images/hero/banner.jpg
menu:
  sidebar:
    name: Semana 4
    identifier: tecyecoSemana 4
    parent: tecyeco-folder
    weight: 5
tags: ["Tecnología y ecología humana", "Maestría - Psicología"]
math: true
draft: true
---


![](/courses/hfc/_index_files/borde.jpg)

## Plan
1. Armas de destrucción matemática
1. Del almacen multinacional de Google a la tienda de la esquina: casos concretos

![](/courses/hfc/_index_files/borde.jpg)



## Armas de destrucción matemática

### Definición

Armas de destrucción matemática -> Weapons of math destruction -> Weapons of Mass destruction -> Armas de destructión masiva (ej. Bombas nucleares)

ADM: la opacidad, la escala y el daño

No porque se usen datos, se hagan predicciones y se implementen decisiones con base en esos resultados tenemos una ADM.

- A veces los puntos ciegos de un modelo no tienen ninguna importancia. Cuando pedimos a Google Maps que nos indique cómo llegar a un lugar, modela el mundo como una serie de carreteras, túneles y puentes. Ignora los edificios, porque no son relevantes para la tarea. Cuando el software de aviónica guía a un avión, modela el viento, la velocidad del avión y la pista de aterrizaje en tierra, pero no las calles, los túneles, los edificios, ni las personas.Los puntos ciegos de un modelo reflejan las opiniones y prioridades de sus creadores

##### "Los modelos son opiniones integradas en matemáticas".

Escala:

Falta de transparencia: 

> Un algoritmo procesa un montón de estadísticas y produce como resultado una cierta probabilidad de que una persona concreta pueda ser un mal empleado, un prestatario de riesgo, un terrorista o un pésimo maestro. Esa probabilidad se condensa en una puntuación, que puede llegar a destrozar la vida de alguien. Y, sin embargo, cuando esa persona decide defenderse, las «sugerentes» pruebas en contra del veredicto son insuficientes para aclarar las cosas.

Daño:

>  Y las víctimas? Bueno, un científico de datos nos diría que ningún sistema estadístico es perfecto. Esas personas son daños colaterales. Y, con frecuencia, como en el caso de Sarah Wysocki, son consideradas indignas y prescindibles. Olvidémonos de las víctimas por un momento, nos diría, y pensemos en todas las personas que reciben sugerencias provechosas de los motores de recomendación y que encuentran música que les apasiona en la radio en línea Pandora, su trabajo ideal en LinkedIn o quizá el amor de su vida en Match.com. Pensemos en la prodigiosa escala de estos modelos e ignoremos las imperfecciones

### Modelos de beisbol

> Los modelos del béisbol, en general, son razonables. Son transparentes y se actualizan constantemente, y tanto los supuestos como las conclusiones son claros y accesibles para cualquiera. Estos modelos se nutren de las estadísticas de cada partido, no de valores sustitutivos, y las personas que son objeto de la modelación entienden el proceso y comparten el objetivo del modelo: ganar la Serie Mundial de béisbol (aunque esto no evite que muchos jugadores refunfuñen por las valoraciones de algún modelo cuando llega la temporada de fichajes: «Es cierto que tuve 200 outs, pero ¿qué pasa con todos mis jonrones…?»).


### Modelo de comidas para la familiar 

> Desde mi posición estratégica dentro del segundo modelo, creo que tampoco hay nada de malo en el hipotético modelo de comidas para mi familia. Si mis hijos quisieran conocer las premisas subyacentes al modelo, tanto las de naturaleza económica como las dietéticas, yo estaría encantada de facilitárselas. Y, aunque a veces se quejan cuando ven algo verde en el plato, si se les pregunta en serio, admiten que comparten los objetivos de comodidad, economía, salud y buen sabor —aunque puede que los ponderen de manera diferente en sus propios modelos (y podrán crearlos en cuanto empiecen a comprarse su propia comida)—.

> Debo añadir que es muy poco probable que mi modelo llegue a alcanzar una gran escala. No me imagino a los grandes almacenes de descuento Walmart, al Departamento de Agricultura de Estados Unidos ni a ningún otro titán adoptando mi app e imponiéndosela a cientos de millones de personas, como hacen con algunas de las ADM de las que hablaremos en este libro. No, mi modelo es benigno, especialmente porque es muy poco probable que llegue a salir de mi cabeza y alguien lo formalice para convertirlo en un programa informático.

### Modelo reincidencia 

> El ejemplo del modelo de reincidencia que hemos visto al final del capítulo, sin embargo, es algo completamente diferente. Despide un olor familiar y nocivo. Hagamos con él un rápido ejercicio de taxonomía de las ADM y veamos dónde encaja.
La primera pregunta; aunque el participante sea consciente de que es objeto de una modelación o de para qué se utiliza el modelo, ¿es el modelo opaco o incluso invisible? Bien, la mayoría de los detenidos a los que se les pide que rellenen un cuestionario obligatorio no son tontos. Como mínimo tendrán razones para sospechar que la información que faciliten será utilizada contra ellos para controlarlos durante su estancia en prisión o quizá para encerrarlos durante más tiempo. Saben de qué va la cosa. Pero los funcionarios de prisiones también lo saben. Y no dirán nada sobre la finalidad del cuestionario LSI-R. Saben que, si explican para qué se utiliza, muchos reclusos intentarán hacer trampas y contestarán a las preguntas de forma que parezca que serán ciudadanos ejemplares en cuanto salgan del trullo. Por lo tanto, a los reclusos se les dice lo menos posible y nunca se les informa de la puntuación de riesgo que han obtenido.

> Y esto es algo que se repite en muchos otros casos. Los modelos opacos e invisibles son lo habitual, mientras que los modelos transparentes son raras excepciones. Nos modelan como clientes y telespectadores tirados en el sofá, como pacientes y solicitantes de préstamos, y apenas nos damos cuenta —incluso en los formularios que firmamos alegremente—. Incluso cuando los modelos actúan bien, su opacidad genera una sensación de injusticia, Si un acomodador nos dice, al llegar a un concierto al aire libre que no podemos sentarnos en las diez primeras filas de asientos, puede que pensemos que eso es inaceptable. Sin embargo, si nos explica que las diez primeras filas están reservadas para personas en silla de ruedas, nos parecería perfectamente lógico. La transparencia importa, marca la diferencia.

> Pese a todo, un gran número de empresas se toman muchas molestias por ocultar los resultados de sus modelos o incluso su existencia. Una justificación común es que el algoritmo es un «secreto industrial» crucial para su actividad. Afirman que es propiedad intelectual y la defenderán con legiones de abogados y grupos de presión si es necesario. En el caso de los gigantes web como Google, Amazon y Facebook, solo sus algoritmos hechos meticulosamente a medida valen cientos de miles de millones de dólares. Las ADM son, por su diseño, cajas negras inescrutables. Y esto hace que sea especialmente difícil contestar categóricamente a la segunda pregunta: ¿opera el modela en contra de los intereses del sujeto? En otras palabras, ¿es injusto? ¿Daña o destruye vidas?

### Comparación con la frenología y problema de la estadística

>  Cuando pienso en las formas interesadas y poco rigurosas en las que las empresas utilizan los datos, a menudo me viene a la cabeza la frenología, una pseudociencia que estuvo de moda durante un breve periodo en el siglo XIX. Los frenólogos pasaban los dedos por el cráneo del paciente buscando protuberancias y hendiduras. Cada uno de estos elementos, según la frenología, estaba relacionado con distintos rasgos de la personalidad presentes en veintisiete regiones diferentes del cerebro. La conclusión del frenólogo solía coincidir con lo que observaba en el paciente. Si un paciente tenía ansiedad o sufría de alcoholismo, el análisis del cráneo solía revelar protuberancias y hendiduras que se correspondían con esa observación, lo que, a su vez, reforzaba la fe en la ciencia de la frenología.

- Este fenómeno es conocido en estadística como la paradoja de Simpson: se da cuando un conjunto de datos muestra una tendencia, pero, al descomponer dicho conjunto en subgrupos, aparece la tendencia opuesta en cada uno de ellos individualmente.


### Ejemplos 

- Modelo de medición de éxito de profesores del distrito
- Modelo de reincidencia criminal
- Modelo de preferencias electorales
- Modelo para publicidad



## Del almacen multinacional de Google a la tienda de la esquina: casos concretos

###  Publicidad

> El inversor nos resumió el brillante futuro de la publicidad selectiva, Los internautas suministran grandes cantidades de datos y, al hacerlo, están entregando a los anunciantes la capacidad de descubrir hasta el mínimo detalle sobre sus vidas. Esto permitirá a las empresas lanzar acciones específicamente dirigidas a los consumidores precisamente en el momento y en el lugar adecuado y utilizando la información que consideren más valiosa.

> Tal y como lo veía él, la mayoría de la gente se opone a la publicidad porque el contenido de los anuncios que ven les resulta indiferente, En el futuro esto no será así. En teoría, las personas que aparecían en su exclusiva demostración estarían encantadas de ver anuncios hechos a medida para ellas, con casas en venta en las Bahamas, botellas de aceite de oliva virgen prensado a mano o jets privados en multipropiedad. 

> La Universidad de Phoenix se gastaba más de 50 millones de dólares solo en anuncios de Google con el objetivo de dirigirse de forma selectiva a las personas pobres para ofrecerles el cebo de la movilidad social.

#### Este tipo de publicidad encuentra la desigualdad y se da un festín a su costa

> Allá donde encontremos la ignorancia combinada con una gran necesidad es muy probable ver anuncios depredadores 

> La vulnerabilidad vale su peso en oro. 

#### El reto de la publicidad y cómo las redes lo "solucionan"

>  Todo esto se complica un poco porque las distintas campañas con diferentes mensajes interactúan unas con otras y no es posible medir gran parte del impacto. Por ejemplo, ¿incrementan los anuncios en los autobuses la probabilidad de que un posible estudiante responda a una llamada de teléfono? Resulta difícil responder a esta pregunta. Es más fácil hacer un seguimiento de los mensajes en línea, y las universidades privadas con ánimo de lucro tienen la capacidad necesaria para recopilar datos vitales de cada posible estudiante —dónde viven y las páginas web que han visitado—.

>  Sin embargo, desde que se creó Internet, personas de todo el mundo han producido trillones de palabras sobre nuestras vidas y nuestro trabajo, nuestras compras y nuestras relaciones de amistad. Al hacerlo, hemos construido sin darnos cuenta el mayor corpus de aprendizaje que haya existido nunca para los programas de lenguaje natural. Cuando pasamos del papel al correo electrónico y a las redes sociales, los ordenadores pudieron empezar a estudiar nuestras palabras, a compararlas con otras y a recopilar cierta información sobre su contexto. El progreso ha sido rápido y drástico. En 2011, Apple apenas logró impresionar al mundo de la tecnología con su «asistente personal» con lenguaje natural Siri. Esta tecnología solo podía conversar en ciertas áreas y cometía errores graciosos. A la mayoría de la gente le pareció prácticamente inútil. Sin embargo, ahora se oye a mucha gente hablándole a su móvil en cualquier momento, le piden la previsión del tiempo, el resultado del partido o indicaciones para dirigirse a algún sitio. En algún momento entre 2008 y 2015, más o menos, las capacidades lingüísticas de los algoritmos avanzaron del nivel de preescolar a quinto de primaria, y en algunas aplicaciones incluso a niveles mucho más avanzados

### Conseguir Empleo

>  La cuestión relevante para este libro en el caso que acabamos de ver es la forma en que los sistemas automáticos nos juzgan cuando estamos buscando empleo y qué criterios evalúan

>  Evidentemente, estos programas de selección y contratación no pueden incorporar información sobre cómo será realmente el rendimiento del trabajador en la empresa. Eso pertenece al futuro y, por lo tanto, no se conoce. De modo que, al igual que otros muchos programas de big data, emplean valores sustitutivos o proxies.

#### Proxies


Cuando no podemos medir X pero sabemos que se correlaciona con una variable Y que sí puede ser medida, usamos Y como un proxy para X.

¿Ejemplos?

El problema con los proxies es que pueden fomentar incentivos perversos. Se puede maximizar un proxy sin preocuparse por el objetivo original. El proxy deja de ser un proxy.

Ejemplos

1. cambio de valores en un partido de fútbol. Medir el éxito con base en el reconocimiento en lugar de goles, o asistencia.

1. Cambio de valores en educación superior. Medir el éxito con base en las calificaciones en lugar del aprendizaje.

Cuando medimos proxies, abrimos la puerta a incentivos perversos:

  En India, se implementó una política de incentivos económicos para reducir la población de serpientes venenosas. Se ofrecía una recompensa monetaria a los ciudadanos por cada serpiente venenosa que capturaran y entregaran a las autoridades locales. Sin embargo, esta medida tuvo un efecto inesperado y contraproducente. En lugar de disminuir, la población de serpientes venenosas aumentó significativamente. ¿La razón? Las personas comenzaron a criar serpientes venenosas con el único propósito de reclamar la recompensa. Este curioso caso ilustra cómo la implementación de incentivos económicos sin considerar las posibles consecuencias puede tener un impacto negativo en la comunidad y el ecosistema local, generando un riesgo para la seguridad de las personas y desequilibrando el equilibrio natural del entorno. Los incentivos tangibles (como el dinero o las notas) o simbólicos (como las caritas felices o las estrellas doradas) pueden influir en el comportamiento de las personas de maneras inesperadas y subraya la necesidad de un enfoque reflexivo y holístico al diseñar políticas y programas de incentivos. La lección aprendida de esta historia es que, al implementar incentivos, es crucial considerar no solo los resultados inmediatos deseados, sino también las posibles ramificaciones y efectos secundarios para evitar consecuencias no deseadas.


--- 

>  «La principal finalidad del test —cuenta Roland Behm— no es encontrar al mejor empleado, sino excluir a tantas personas como sea posible de la manera más barata posible»  

Parte del problema se da porque no hay un cuidado del algoritmo:

> Se molestará alguno de los directivos de Kroger en analizar el test de personalidad e investigar por qué se equivocaron tanto? Seguro que no. La diferencia es la siguiente: los equipos de baloncesto gestionan personas individuales con un valor potencial de millones de dólares cada una. Sus sistemas analíticos son cruciales para su ventaja competitiva y están ávidos de datos. Sin retroalimentación constante, sus sistemas se quedan anticuados y resultan inútiles. Por el contrario, las empresas que contratan a trabajadores por el sueldo mínimo, gestionan rebaños

> El modelo consideraba que era más probable que rotaran los candidatos que vivían más lejos de las instalaciones en las que debían ejercer su trabajo. Esta correlación tiene sentido: es agotador pasar mucho tiempo en el trayecto al trabajo. Sin embargo, los directivos de Xerox observaron otra correlación curiosa. Muchas de las personas que sufrían esos largos desplazamientos venían al trabajo desde barrios pobres. Y hay que decir a favor de Xerox que eliminaron del modelo estos datos geográficos pese a su alta correlación con la rotación de personal. La empresa sacrificó un poco de eficiencia a cambio de ser más justos

### Profesores del distrito

> en 2009, Michelle Rhee puso en marcha un plan para extirpar del sistema a los docentes de bajo rendimiento. Esta era la tendencia generalizada en los distritos escolares con problemas en todo el país y, desde el punto de vista de la ingeniería de sistemas, este razonamiento tiene mucho sentido. Hay que evaluar a los profesores, deshacerse de los peores y colocar a los mejores donde puedan producir el mayor efecto positivo posible. En el lenguaje de los científicos de datos, de este modo «se optimiza» el sistema escolar y presuntamente se garantizan mejores resultados para los alumnos. Exceptuando a los «malos» profesores, ¿quién podría no estar de acuerdo con este razonamiento?

El daño no está determinado por la intención. (Recuerden el efecto Knobe y la relación entre la intencionalidad y la valuación moral.)


> En empresas de big data como Google, por el contrario, los investigadores están constantemente haciendo pruebas y controlan miles de variables. Pueden preparar dos versiones de un mismo anuncio —una con las letras en azul y otra en rojo—, presentar cada una de estas versiones a diez millones de personas y hacer un seguimiento para saber cuál de las dos recibe más clics. Utilizan esta retroalimentación para pulir sus algoritmos y ajustar su funcionamiento. 

Parte del problema está en el cuidado del algortimo. Depende de la cantidad. Hay daño a escala, pero no necesariamente examen en escala.

> intentar puntuar la eficacia de un docente analizando los resultados de una prueba de solo veinticinco o treinta alumnos no tiene solidez estadística y es incluso ridículo. El número de valores es insuficiente si se tiene en cuenta todo lo que puede fallar. De hecho, si quisiéramos analizar a los docentes con el rigor estadístico de un motor de búsqueda, tendríamos que probarlos en miles o incluso millones de alumnos seleccionados al azar.

La pregunta: ¿Hacia dónde va dirigido el precio o las consecuencias del algortimo?

>  Esto nos lleva a hablar de otra característica común de las ADM: suelen castigar a los pobres. Esto se debe, en parte, a que han sido diseñadas para evaluar grandes cantidades de personas. Están especializadas en trabajar con grandes volúmenes, y son baratas. Eso forma parte de su atractivo. Los ricos, en cambio, reciben a menudo un trato más personal.


>  De este modo, las consultoras como Mathematica pueden cobrar más, aunque este secretismo sirve también a otros propósitos: se supone que, si las personas evaluadas no saben cómo se hace la evaluación, es menos probable que intenten engañar al sistema.

Ejemplo de que conocer el sistema permite engañar el sistema?





### Armas de destrucción matemática. 

Privacidad y Poder. VELIZ, C. (2021) Privacidad es poder: datos, vigilancia y libertad en la era digital. 
Barcelona: Editorial Debate. Cap 3.  


Emili: cap 10
KAren cap 6
Paola: cap 4
Gloria: ciudadano: Cap 10
Diana Cap 7. 


